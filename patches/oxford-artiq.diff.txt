diff --git a/artiq/dashboard/experiments.py b/artiq/dashboard/experiments.py
index 6095a3466..be8b198f6 100644
--- a/artiq/dashboard/experiments.py
+++ b/artiq/dashboard/experiments.py
@@ -164,7 +164,7 @@ class _ArgumentEditor(QtWidgets.QTreeWidget):

     async def _recompute_argument(self, name):
         try:
-            expdesc = await self.manager.compute_expdesc(self.expurl)
+            expdesc, _ = await self.manager.compute_expdesc(self.expurl)
         except:
             logger.error("Could not recompute argument '%s' of '%s'",
                          name, self.expurl, exc_info=True)
@@ -216,6 +216,12 @@ class _ArgumentEditor(QtWidgets.QTreeWidget):
                 pass
         self.verticalScrollBar().setValue(state["scroll"])

+    def about_to_submit(self):
+        pass
+
+    def about_to_close(self):
+        pass
+

 log_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]

@@ -241,7 +247,8 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):
         self.manager = manager
         self.expurl = expurl

-        self.argeditor = _ArgumentEditor(self.manager, self, self.expurl)
+        editor_class = self.manager.get_argument_editor_class(expurl)
+        self.argeditor = editor_class(self.manager, self, self.expurl)
         self.layout.addWidget(self.argeditor, 0, 0, 1, 5)
         self.layout.setRowStretch(0, 1)

@@ -369,6 +376,7 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):
         self.hdf5_load_directory = os.path.expanduser("~")

     def submit_clicked(self):
+        self.argeditor.about_to_submit()
         try:
             self.manager.submit(self.expurl)
         except:
@@ -391,9 +399,9 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):

     async def _recompute_arguments_task(self, overrides=dict()):
         try:
-            expdesc = await self.manager.compute_expdesc(self.expurl)
+            expdesc, ui_name = await self.manager.compute_expdesc(self.expurl)
         except:
-            logger.error("Could not recompute experiment description of '%s'",
+            logger.error("Could not recompute arguments of '%s'",
                          self.expurl, exc_info=True)
             return
         arginfo = expdesc["arginfo"]
@@ -404,12 +412,13 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):
                 arginfo[k][0]["default"].insert(0, v)
             else:
                 arginfo[k][0]["default"] = v
-        self.manager.initialize_submission_arguments(self.expurl, arginfo)
+        self.manager.initialize_submission_arguments(self.expurl, arginfo, ui_name)

         argeditor_state = self.argeditor.save_state()
         self.argeditor.deleteLater()

-        self.argeditor = _ArgumentEditor(self.manager, self, self.expurl)
+        editor_class = self.manager.get_argument_editor_class(self.expurl)
+        self.argeditor = editor_class(self.manager, self, self.expurl)
         self.argeditor.restore_state(argeditor_state)
         self.layout.addWidget(self.argeditor, 0, 0, 1, 5)

@@ -422,7 +431,7 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):

     async def _recompute_sched_options_task(self):
         try:
-            expdesc = await self.manager.compute_expdesc(self.expurl)
+            expdesc, _ = await self.manager.compute_expdesc(self.expurl)
         except:
             logger.error("Could not recompute experiment description of '%s'",
                          self.expurl, exc_info=True)
@@ -435,6 +444,7 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):
         self.pipeline_name.setText(scheduling["pipeline_name"])
         self.flush.setChecked(scheduling["flush"])

+
     def _load_hdf5_clicked(self):
         asyncio.ensure_future(self._load_hdf5_task())

@@ -473,6 +483,7 @@ class _ExperimentDock(QtWidgets.QMdiSubWindow):
         await self._recompute_arguments_task(arguments)

     def closeEvent(self, event):
+        self.argeditor.about_to_close()
         self.sigClosed.emit()
         QtWidgets.QMdiSubWindow.closeEvent(self, event)

@@ -544,7 +555,11 @@ class _QuickOpenDialog(QtWidgets.QDialog):


 class ExperimentManager:
-    def __init__(self, main_window,
+    #: Registry for custom argument editor classes, indexed by the experiment
+    #: argument_ui key string.
+    argument_ui_classes = dict()
+
+    def __init__(self, main_window, dataset_sub,
                  explist_sub, schedule_sub,
                  schedule_ctl, experiment_db_ctl):
         self.main_window = main_window
@@ -555,7 +570,10 @@ class ExperimentManager:
         self.submission_scheduling = dict()
         self.submission_options = dict()
         self.submission_arguments = dict()
+        self.argument_ui_names = dict()

+        self.datasets = dict()
+        dataset_sub.add_setmodel_callback(self.set_dataset_model)
         self.explist = dict()
         explist_sub.add_setmodel_callback(self.set_explist_model)
         self.schedule = dict()
@@ -570,6 +588,9 @@ class ExperimentManager:
         quick_open_shortcut.setContext(QtCore.Qt.ApplicationShortcut)
         quick_open_shortcut.activated.connect(self.show_quick_open)

+    def set_dataset_model(self, model):
+        self.datasets = model
+
     def set_explist_model(self, model):
         self.explist = model.backing_store

@@ -586,6 +607,17 @@ class ExperimentManager:
         else:
             raise ValueError("Malformed experiment URL")

+    def get_argument_editor_class(self, expurl):
+        ui_name = self.argument_ui_names.get(expurl, None)
+        if not ui_name and expurl[:5] == "repo:":
+            ui_name = self.explist.get(expurl[5:], {}).get("argument_ui", None)
+        if ui_name:
+            result = self.argument_ui_classes.get(ui_name, None)
+            if result:
+                return result
+            logger.warning("Ignoring unknown argument UI '%s'", ui_name)
+        return _ArgumentEditor
+
     def get_submission_scheduling(self, expurl):
         if expurl in self.submission_scheduling:
             return self.submission_scheduling[expurl]
@@ -615,7 +647,7 @@ class ExperimentManager:
             self.submission_options[expurl] = options
             return options

-    def initialize_submission_arguments(self, expurl, arginfo):
+    def initialize_submission_arguments(self, expurl, arginfo, ui_name):
         arguments = OrderedDict()
         for name, (procdesc, group, tooltip) in arginfo.items():
             state = procdesc_to_entry(procdesc).default_state(procdesc)
@@ -626,6 +658,7 @@ class ExperimentManager:
                 "state": state,  # mutated by entries
             }
         self.submission_arguments[expurl] = arguments
+        self.argument_ui_names[expurl] = ui_name
         return arguments

     def get_submission_arguments(self, expurl):
@@ -635,9 +668,9 @@ class ExperimentManager:
             if expurl[:5] != "repo:":
                 raise ValueError("Submission arguments must be preinitialized "
                                  "when not using repository")
-            arginfo = self.explist[expurl[5:]]["arginfo"]
-            arguments = self.initialize_submission_arguments(expurl, arginfo)
-            return arguments
+            class_desc = self.explist[expurl[5:]]
+            return self.initialize_submission_arguments(expurl,
+                class_desc["arginfo"], class_desc.get("argument_ui", None))

     def open_experiment(self, expurl):
         if expurl in self.open_experiments:
@@ -739,13 +772,15 @@ class ExperimentManager:
             revision = None
         description = await self.experiment_db_ctl.examine(
             file, use_repository, revision)
-        return description[class_name]
+        class_desc = description[class_name]
+        return class_desc, class_desc.get("argument_ui", None)

     async def open_file(self, file):
         description = await self.experiment_db_ctl.examine(file, False)
         for class_name, class_desc in description.items():
             expurl = "file:{}@{}".format(class_name, file)
-            self.initialize_submission_arguments(expurl, class_desc["arginfo"])
+            self.initialize_submission_arguments(expurl, class_desc["arginfo"],
+                class_desc.get("argument_ui", None))
             if expurl in self.open_experiments:
                 self.open_experiments[expurl].close()
             self.open_experiment(expurl)
@@ -758,6 +793,7 @@ class ExperimentManager:
             "options": self.submission_options,
             "arguments": self.submission_arguments,
             "docks": self.dock_states,
+            "argument_uis": self.argument_ui_names,
             "open_docks": set(self.open_experiments.keys())
         }

@@ -768,6 +804,7 @@ class ExperimentManager:
         self.submission_scheduling = state["scheduling"]
         self.submission_options = state["options"]
         self.submission_arguments = state["arguments"]
+        self.argument_ui_names = state.get("argument_uis", {})
         for expurl in state["open_docks"]:
             self.open_experiment(expurl)

diff --git a/artiq/frontend/artiq_dashboard.py b/artiq/frontend/artiq_dashboard.py
index bd9127f9d..bea14f5ad 100755
--- a/artiq/frontend/artiq_dashboard.py
+++ b/artiq/frontend/artiq_dashboard.py
@@ -3,6 +3,7 @@
 import argparse
 import asyncio
 import atexit
+import importlib
 import os
 import logging
 import sys
@@ -43,6 +44,9 @@ def get_argparser():
     parser.add_argument(
         "--db-file", default=None,
         help="database file for local GUI settings")
+    parser.add_argument(
+        "-p", "--load-plugin", dest="plugin_modules", action="append",
+        help="Python module to load on startup")
     common_args.verbosity_args(parser)
     return parser

@@ -95,6 +99,10 @@ def main():
     args = get_argparser().parse_args()
     widget_log_handler = log.init_log(args, "dashboard")

+    if args.plugin_modules:
+        for mod in args.plugin_modules:
+            importlib.import_module(mod)
+
     if args.db_file is None:
         args.db_file = os.path.join(get_user_config_dir(),
                            "artiq_dashboard_{server}_{port}.pyon".format(
@@ -160,6 +168,7 @@ def main():

     # create UI components
     expmgr = experiments.ExperimentManager(main_window,
+                                           sub_clients["datasets"],
                                            sub_clients["explist"],
                                            sub_clients["schedule"],
                                            rpc_clients["schedule"],
@@ -178,7 +187,9 @@ def main():
                                        rpc_clients["dataset_db"])
     smgr.register(d_datasets)

-    d_applets = applets_ccb.AppletsCCBDock(main_window, sub_clients["datasets"])
+    d_applets = applets_ccb.AppletsCCBDock(main_window, sub_clients["datasets"],
+        extra_substitutes={"server": args.server, "port_notify": args.port_notify,
+        "port_control": args.port_control})
     atexit_register_coroutine(d_applets.stop)
     smgr.register(d_applets)
     broadcast_clients["ccb"].notify_cbs.append(d_applets.ccb_notify)
diff --git a/artiq/frontend/artiq_master.py b/artiq/frontend/artiq_master.py
index 1a5073692..26ecd5dc1 100755
--- a/artiq/frontend/artiq_master.py
+++ b/artiq/frontend/artiq_master.py
@@ -15,7 +15,7 @@ from sipyco.asyncio_tools import atexit_register_coroutine

 from artiq import __version__ as artiq_version
 from artiq.master.log import log_args, init_log
-from artiq.master.databases import DeviceDB, DatasetDB
+from artiq.master.databases import DeviceDB, DatasetDB, DatasetNamespaces
 from artiq.master.scheduler import Scheduler
 from artiq.master.rid_counter import RIDCounter
 from artiq.master.experiments import (FilesystemBackend, GitBackend,
@@ -98,6 +98,10 @@ def main():
     dataset_db = DatasetDB(args.dataset_db)
     dataset_db.start()
     atexit_register_coroutine(dataset_db.stop)
+
+    dataset_namespaces = DatasetNamespaces(dataset_db)
+    atexit_register_coroutine(dataset_namespaces.stop)
+
     worker_handlers = dict()

     if args.git:
@@ -107,7 +111,8 @@ def main():
     experiment_db = ExperimentDB(repo_backend, worker_handlers)
     atexit.register(experiment_db.close)

-    scheduler = Scheduler(RIDCounter(), worker_handlers, experiment_db)
+    scheduler = Scheduler(RIDCounter(), worker_handlers, experiment_db,
+                          dataset_namespaces)
     scheduler.start()
     atexit_register_coroutine(scheduler.stop)

@@ -145,6 +150,7 @@ def main():
         "explist": experiment_db.explist,
         "explist_status": experiment_db.status
     })
+    dataset_namespaces.set_publisher(server_notify)
     loop.run_until_complete(server_notify.start(
         bind, args.port_notify))
     atexit_register_coroutine(server_notify.stop)
diff --git a/artiq/gui/applets.py b/artiq/gui/applets.py
index 178593a07..ab190fa75 100644
--- a/artiq/gui/applets.py
+++ b/artiq/gui/applets.py
@@ -93,7 +93,7 @@ class AppletIPCServer(AsyncioParentComm):


 class _AppletDock(QDockWidgetCloseDetect):
-    def __init__(self, datasets_sub, uid, name, spec):
+    def __init__(self, datasets_sub, uid, name, spec, extra_substitutes):
         QDockWidgetCloseDetect.__init__(self, "Applet: " + name)
         self.setObjectName("applet" + str(uid))

@@ -104,6 +104,7 @@ class _AppletDock(QDockWidgetCloseDetect):
         self.datasets_sub = datasets_sub
         self.applet_name = name
         self.spec = spec
+        self.extra_substitutes = extra_substitutes

         self.starting_stopping = False

@@ -152,7 +153,8 @@ class _AppletDock(QDockWidgetCloseDetect):
             python = sys.executable.replace("\\", "\\\\")
             command = command_tpl.safe_substitute(
                 python=python,
-                artiq_applet=python + " -m artiq.applets."
+                artiq_applet=python + " -m artiq.applets.",
+                **self.extra_substitutes
             )
             logger.debug("starting command %s for %s", command, self.applet_name)
             await self.start_process(shlex.split(command), None)
@@ -314,7 +316,7 @@ class _CompleterDelegate(QtWidgets.QStyledItemDelegate):


 class AppletsDock(QtWidgets.QDockWidget):
-    def __init__(self, main_window, datasets_sub):
+    def __init__(self, main_window, datasets_sub, extra_substitutes = {}):
         QtWidgets.QDockWidget.__init__(self, "Applets")
         self.setObjectName("Applets")
         self.setFeatures(QtWidgets.QDockWidget.DockWidgetMovable |
@@ -322,6 +324,7 @@ class AppletsDock(QtWidgets.QDockWidget):

         self.main_window = main_window
         self.datasets_sub = datasets_sub
+        self.extra_substitutes = extra_substitutes
         self.applet_uids = set()

         self.table = QtWidgets.QTreeWidget()
@@ -420,7 +423,7 @@ class AppletsDock(QtWidgets.QDockWidget):
             self.table.itemChanged.connect(self.item_changed)

     def create(self, item, name, spec):
-        dock = _AppletDock(self.datasets_sub, item.applet_uid, name, spec)
+        dock = _AppletDock(self.datasets_sub, item.applet_uid, name, spec, self.extra_substitutes)
         self.main_window.addDockWidget(QtCore.Qt.RightDockWidgetArea, dock)
         dock.setFloating(True)
         asyncio.ensure_future(dock.start())
@@ -626,7 +629,7 @@ class AppletsDock(QtWidgets.QDockWidget):
     def restore_state_item(self, state, parent):
         for wis in state:
             if wis[0] == "applet":
-                _, uid, enabled, name, spec, geometry = wis
+                _, uid, enabled, name, spec, geometry, *_ = wis
                 if spec["ty"] not in {"command", "code"}:
                     raise ValueError("Invalid applet spec type: "
                                      + str(spec["ty"]))
diff --git a/artiq/gui/tools.py b/artiq/gui/tools.py
index bc681bb77..7d6fb0a2f 100644
--- a/artiq/gui/tools.py
+++ b/artiq/gui/tools.py
@@ -42,6 +42,10 @@ class LayoutWidget(QtWidgets.QWidget):
     def __init__(self, parent=None):
         QtWidgets.QWidget.__init__(self, parent)
         self.layout = QtWidgets.QGridLayout()
+
+        # Reduce amount of whitespace.
+        self.layout.setContentsMargins(3, 3, 3, 3)
+
         self.setLayout(self.layout)

     def addWidget(self, item, row=0, col=0, rowspan=1, colspan=1):
diff --git a/artiq/language/units.py b/artiq/language/units.py
index 13f6f1535..569fb964b 100644
--- a/artiq/language/units.py
+++ b/artiq/language/units.py
@@ -19,4 +19,4 @@ _register_unit("Hz", "m_kMG")
 _register_unit("dB", "_")
 _register_unit("V", "um_k")
 _register_unit("A", "um_")
-_register_unit("W", "um_")
+_register_unit("W", "num_")
diff --git a/artiq/master/databases.py b/artiq/master/databases.py
index 977cfae44..10b644bf4 100644
--- a/artiq/master/databases.py
+++ b/artiq/master/databases.py
@@ -1,4 +1,5 @@
 import asyncio
+import copy
 import tokenize

 from sipyco.sync_struct import Notifier, process_mod, update_from_dict
@@ -42,6 +43,9 @@ class DatasetDB(TaskObject):
             file_data = pyon.load_file(self.persist_file)
         except FileNotFoundError:
             file_data = dict()
+
+        # Maps dataset keys to tuples (persist, value) containing the data and
+        # indicating whether to save the key to the ``persist_file``.
         self.data = Notifier({k: (True, v) for k, v in file_data.items()})

     def save(self):
@@ -74,3 +78,61 @@ class DatasetDB(TaskObject):
     def delete(self, key):
         del self.data[key]
     #
+
+
+def _rid_namespace_name(rid):
+    return "datasets_rid_{}".format(rid)
+
+
+class DatasetNamespaces:
+    """Manages source namespaces for datasets.
+    """
+
+    def __init__(self, dataset_db, gc_timeout_seconds = 10 * 60):
+        #: Duration namespaces are kept alive (for clients to access) after they
+        #: have been finished, in seconds.
+        self.gc_timeout_seconds = gc_timeout_seconds
+
+        self._dataset_db = dataset_db
+        self._publisher = None
+        self._rid_notifiers = dict()
+        self._gc_tasks = dict()
+
+    async def stop(self):
+        tasks = self._gc_tasks.values()
+        if not tasks:
+            return
+        for t in tasks:
+            t.cancel()
+        await asyncio.wait(tasks)
+
+    def set_publisher(self, publisher):
+        assert self._publisher is None
+        self._publisher = publisher
+        for rid in self._rid_notifiers.keys():
+            self._publish_rid(rid)
+
+    def init_rid(self, rid):
+        notifier = Notifier(dict())
+        self._rid_notifiers[rid] = notifier
+        self._publish_rid(rid)
+
+    def update_rid_namespace(self, rid, mod):
+        process_mod(self._rid_notifiers[rid], mod)
+        # Forward to global namespace as well.
+        self._dataset_db.update(copy.deepcopy(mod))
+
+    def finish_rid(self, rid):
+        if rid not in self._rid_notifiers:
+            return
+
+        async def gc():
+            await asyncio.sleep(self.gc_timeout_seconds)
+            self._publisher.remove_notifier(_rid_namespace_name(rid))
+            del self._rid_notifiers[rid]
+            del self._gc_tasks[rid]
+        self._gc_tasks[rid] = asyncio.ensure_future(gc())
+
+    def _publish_rid(self, rid):
+        if self._publisher:
+            self._publisher.add_notifier(_rid_namespace_name(rid), self._rid_notifiers[rid])
diff --git a/artiq/master/experiments.py b/artiq/master/experiments.py
index b9a46d7ba..6d86e1b89 100644
--- a/artiq/master/experiments.py
+++ b/artiq/master/experiments.py
@@ -30,7 +30,6 @@ class _RepoScanner:
             raise
         for class_name, class_desc in description.items():
             name = class_desc["name"]
-            arginfo = class_desc["arginfo"]
             if "/" in name:
                 logger.warning("Character '/' is not allowed in experiment "
                                "name (%s)", name)
@@ -47,7 +46,8 @@ class _RepoScanner:
             entry = {
                 "file": filename,
                 "class_name": class_name,
-                "arginfo": arginfo,
+                "arginfo": class_desc["arginfo"],
+                "argument_ui": class_desc["argument_ui"],
                 "scheduler_defaults": class_desc["scheduler_defaults"]
             }
             entry_dict[name] = entry
diff --git a/artiq/master/scheduler.py b/artiq/master/scheduler.py
index d978fa2f9..ce2959a5f 100644
--- a/artiq/master/scheduler.py
+++ b/artiq/master/scheduler.py
@@ -1,18 +1,21 @@
 import asyncio
 import logging
-from enum import Enum
+from enum import Enum, unique
 from time import time
+from functools import partial

-from sipyco.sync_struct import Notifier
+from sipyco.sync_struct import Notifier, process_mod
 from sipyco.asyncio_tools import TaskObject, Condition

-from artiq.master.worker import Worker, log_worker_exception
+from artiq.master.worker import (Worker, log_worker_exception, ResumeAction,
+                                 RunResult)
 from artiq.tools import asyncio_wait_or_cancel


 logger = logging.getLogger(__name__)


+@unique
 class RunStatus(Enum):
     pending = 0
     flushing = 1
@@ -23,12 +26,14 @@ class RunStatus(Enum):
     analyzing = 6
     deleting = 7
     paused = 8
+    idle = 9


 def _mk_worker_method(name):
     async def worker_method(self, *args, **kwargs):
         if self.worker.closed.is_set():
-            return True
+            # Worker already killed.
+            return RunResult.completed
         m = getattr(self.worker, name)
         try:
             return await m(*args, **kwargs)
@@ -38,8 +43,7 @@ def _mk_worker_method(name):
             if self.worker.closed.is_set():
                 logger.debug("suppressing worker exception of terminated run",
                              exc_info=True)
-                # Return completion on termination
-                return True
+                return RunResult.completed
             else:
                 raise
     return worker_method
@@ -58,7 +62,17 @@ class Run:
         self.due_date = due_date
         self.flush = flush

-        self.worker = Worker(pool.worker_handlers)
+        # Update datasets through rid namespace.
+        handlers = pool.worker_handlers
+        namespaces = pool.dataset_namespaces
+        if namespaces:
+            namespaces.init_rid(rid)
+            handlers = {
+                **handlers,
+                "update_dataset": partial(namespaces.update_rid_namespace, rid)
+            }
+        self.worker = Worker(handlers)
+
         self.termination_requested = False

         self._status = RunStatus.pending
@@ -113,7 +127,8 @@ class Run:


 class RunPool:
-    def __init__(self, ridc, worker_handlers, notifier, experiment_db):
+    def __init__(self, ridc, worker_handlers, notifier, experiment_db,
+                 dataset_namespaces):
         self.runs = dict()
         self.state_changed = Condition()

@@ -121,6 +136,7 @@ class RunPool:
         self.worker_handlers = worker_handlers
         self.notifier = notifier
         self.experiment_db = experiment_db
+        self.dataset_namespaces = dataset_namespaces

     def submit(self, expid, priority, due_date, flush, pipeline_name):
         # mutates expid to insert head repository revision if None.
@@ -199,13 +215,14 @@ class PrepareStage(TaskObject):
             else:
                 if run.flush:
                     run.status = RunStatus.flushing
-                    while not all(r.status in (RunStatus.pending,
-                                               RunStatus.deleting)
-                                  or r.priority < run.priority
-                                  or r is run
-                                  for r in self.pool.runs.values()):
-                        ev = [self.pool.state_changed.wait(),
-                              run.worker.closed.wait()]
+                    while not all(
+                            r.status in (RunStatus.pending, RunStatus.deleting)
+                            or r.priority < run.priority or r is run
+                            for r in self.pool.runs.values()):
+                        ev = [
+                            self.pool.state_changed.wait(),
+                            run.worker.closed.wait()
+                        ]
                         await asyncio_wait_or_cancel(
                             ev, return_when=asyncio.FIRST_COMPLETED)
                         if run.worker.closed.is_set():
@@ -230,7 +247,26 @@ class RunStage(TaskObject):
         self.pool = pool
         self.delete_cb = delete_cb

-    def _get_run(self):
+        #: Runs that are running/paused, kept in order of ascending priority.
+        self._run_stack = []
+
+        #: Runs that might be idle, i.e. should be resumed with the
+        #: check_idle_only action to check before scheduling them in.
+        self._idle_runs = set()
+
+        self._runs_to_unidle = []
+
+        #: Makes sure `highest_priority_run()` isn't invoked multiple times
+        #: while waiting for experiments to report back idle status. The lock
+        #: should never be contended in normal operation, as only this main
+        #: coroutine (_do) should call `highest_priority_run()` (for
+        #: scheduling, or from within `check_pause()`). Having it is cheap,
+        #: though, and makes sure e.g. tests can call it out-of-band.
+        self._priority_lock = asyncio.Lock()
+
+    def _next_prepared_run(self):
+        """Return the highest-priority run from the pool that is done preparing
+        and ready to be run."""
         prepared_runs = filter(lambda r: r.status == RunStatus.prepare_done,
                                self.pool.runs.values())
         try:
@@ -240,43 +276,165 @@ class RunStage(TaskObject):
             r = None
         return r

-    async def _do(self):
-        stack = []
+    async def _check_if_still_idle(self, run):
+        """Wake up a given run that is assumed to be paused and check whether
+        it should still be considered idle."""
+        if run.termination_requested:
+            return False
+
+        if run.status == RunStatus.deleting:
+            # Idle run was forcibly terminated. Un-idle it so it can be cleaned up in
+            # the main loop.
+            return False
+
+        delete_run = False
+        if run.status == RunStatus.idle:
+            try:
+                run_result = await run.resume(ResumeAction.check_still_idle)
+                # The worker just got killed, e.g. during shutdown, so we need to
+                # make sure not to attempt communication again.
+                if run_result == RunResult.completed:
+                    delete_run = True
+            except:
+                logger.error(
+                    "got worker exception in idle callback, deleting RID %d",
+                    run.rid)
+                log_worker_exception()
+                delete_run = True
+        else:
+            logger.error(
+                "got unexpected status while checking RID %s "
+                "for idleness, deleting: %s", run.rid, run.status)
+            delete_run = True
+
+        if delete_run:
+            self.delete_cb(run.rid)
+            return False
+
+        return run_result == RunResult.idle
+
+    async def highest_priority_run(self):
+        """Return the run to schedule on the next permanent context switch.

+        Blocks for runs to become available if there aren't currently any.
+        """
+        async with self._priority_lock:
+            while True:
+                # Find the first non-idle run on the stack.
+                top_run = None
+                for run in reversed(self._run_stack):
+                    if (run not in self._idle_runs
+                            or not await self._check_if_still_idle(run)):
+                        top_run = run
+                        break
+
+                prepared_run = self._next_prepared_run()
+                if (prepared_run and
+                    (not top_run or
+                     (prepared_run.priority_key() > top_run.priority_key()))):
+
+                    # Insert the prepared run at the correct position of the
+                    # stack.
+                    prepared_priority = prepared_run.priority_key()
+                    idx = len(self._run_stack)
+                    while idx > 0:
+                        priority = self._run_stack[idx - 1].priority_key()
+                        if prepared_priority > priority:
+                            break
+                        idx -= 1
+                    self._run_stack.insert(idx, prepared_run)
+                    top_run = prepared_run
+
+                if top_run:
+                    # Un-idle all runs with lower priority to pause them.
+                    for run in self._run_stack:
+                        if run in self._idle_runs:
+                            self._runs_to_unidle.append(run)
+                            self._idle_runs.remove(run)
+                        if run == top_run:
+                            break
+                    return top_run
+
+                timeout = None if not self._idle_runs else 0.2
+                await asyncio_wait_or_cancel([self.pool.state_changed.wait()],
+                    timeout=timeout)
+
+    async def _do(self):
         while True:
-            next_irun = self._get_run()
-            if not stack or (
-                    next_irun is not None and
-                    next_irun.priority_key() > stack[-1].priority_key()):
-                while next_irun is None:
-                    await self.pool.state_changed.wait()
-                    next_irun = self._get_run()
-                stack.append(next_irun)
-
-            run = stack.pop()
+            # Get the highest-priority run to execute, blocking if necessary.
+            #
+            # At the end of the iteration, `run` will either be removed from
+            # the run stack, or will still be incomplete, with `resume()` to be
+            # invoked again in the future.
+            run = await self.highest_priority_run()
+
+            # Un-idle all the runs that are of lower priority than the run about
+            # to be executed. The worker should immediately pause.
+            for unidle_run in self._runs_to_unidle:
+                if unidle_run == run:
+                    break
+                if unidle_run.status != RunStatus.idle:
+                    logger.error("unexpected status %s pausing RID %s from idle",
+                                 unidle_run.status, unidle_run.rid)
+                unidle_run.status = RunStatus.running
+                unidle_result = RunResult(await
+                                          unidle_run.resume(ResumeAction.pause))
+                if unidle_run.status != RunStatus.running:
+                    logger.error(
+                        "unexpected status %s after pausing RID %s from idle",
+                        unidle_run.status, unidle_run.rid)
+                unidle_run.status = RunStatus.paused
+            self._runs_to_unidle.clear()
+
+            if run.status not in (RunStatus.paused, RunStatus.prepare_done,
+                    RunStatus.idle):
+                if run.status != RunStatus.deleting:
+                    logger.error("unexpected run status %s for RID %s",
+                        run.status, run.rid)
+                if run in self._idle_runs:
+                    self._idle_runs.remove(run)
+                self._run_stack.remove(run)
+                continue
+
             try:
-                if run.status == RunStatus.paused:
+                if run.status == RunStatus.prepare_done:
                     run.status = RunStatus.running
-                    # clear "termination requested" flag now
-                    # so that if it is set again during the resume, this
-                    # results in another exception.
-                    request_termination = run.termination_requested
-                    run.termination_requested = False
-                    completed = await run.resume(request_termination)
+                    run_result = await run.run()
                 else:
+                    if run.termination_requested:
+                        if run.status == RunStatus.idle:
+                            # If the run is currently idle, tell it to pause
+                            # (which will then throw).
+                            action = ResumeAction.pause
+                        else:
+                            action = ResumeAction.request_termination
+                            # Clear "termination requested" flag so another
+                            # exception will be triggered if it is set again
+                            # during the resumed run.
+                            run.termination_requested = False
+                    else:
+                        action = ResumeAction.resume
                     run.status = RunStatus.running
-                    completed = await run.run()
+                    run_result = await run.resume(action)
+
+                run_result = RunResult(run_result)  # no-op type assertion
             except:
-                logger.error("got worker exception in run stage, "
-                             "deleting RID %d", run.rid)
+                logger.error(
+                    "got worker exception in run stage, deleting RID %d",
+                    run.rid)
                 log_worker_exception()
                 self.delete_cb(run.rid)
+                self._run_stack.remove(run)
             else:
-                if completed:
+                if run_result == RunResult.completed:
                     run.status = RunStatus.run_done
+                    self._run_stack.remove(run)
                 else:
-                    run.status = RunStatus.paused
-                    stack.append(run)
+                    if run_result == RunResult.idle:
+                        run.status = RunStatus.idle
+                        self._idle_runs.add(run)
+                    else:
+                        run.status = RunStatus.paused


 class AnalyzeStage(TaskObject):
@@ -311,8 +469,10 @@ class AnalyzeStage(TaskObject):


 class Pipeline:
-    def __init__(self, ridc, deleter, worker_handlers, notifier, experiment_db):
-        self.pool = RunPool(ridc, worker_handlers, notifier, experiment_db)
+    def __init__(self, ridc, deleter, worker_handlers, notifier, experiment_db,
+                 dataset_namespaces):
+        self.pool = RunPool(ridc, worker_handlers, notifier, experiment_db,
+                            dataset_namespaces)
         self._prepare = PrepareStage(self.pool, deleter.delete)
         self._run = RunStage(self.pool, deleter.delete)
         self._analyze = AnalyzeStage(self.pool, deleter.delete)
@@ -335,8 +495,9 @@ class Deleter(TaskObject):
     :meth:`RunPool.delete` is an async function (it needs to close the worker
     connection, etc.), so we maintain a queue of RIDs to delete on a background task.
     """
-    def __init__(self, pipelines):
+    def __init__(self, pipelines, dataset_namespaces):
         self._pipelines = pipelines
+        self._dataset_namespaces = dataset_namespaces
         self._queue = asyncio.Queue()

     def delete(self, rid):
@@ -361,6 +522,8 @@ class Deleter(TaskObject):
             if rid in pipeline.pool.runs:
                 logger.debug("deleting RID %d...", rid)
                 await pipeline.pool.delete(rid)
+                if self._dataset_namespaces:
+                    self._dataset_namespaces.finish_rid(rid)
                 logger.debug("deletion of RID %d completed", rid)
                 break

@@ -383,16 +546,17 @@ class Deleter(TaskObject):


 class Scheduler:
-    def __init__(self, ridc, worker_handlers, experiment_db):
+    def __init__(self, ridc, worker_handlers, experiment_db, dataset_namespaces):
         self.notifier = Notifier(dict())

         self._pipelines = dict()
         self._worker_handlers = worker_handlers
         self._experiment_db = experiment_db
+        self._dataset_namespaces = dataset_namespaces
         self._terminated = False

         self._ridc = ridc
-        self._deleter = Deleter(self._pipelines)
+        self._deleter = Deleter(self._pipelines, dataset_namespaces)

     def start(self):
         self._deleter.start()
@@ -423,7 +587,7 @@ class Scheduler:
             logger.debug("creating pipeline '%s'", pipeline_name)
             pipeline = Pipeline(self._ridc, self._deleter,
                                 self._worker_handlers, self.notifier,
-                                self._experiment_db)
+                                self._experiment_db, self._dataset_namespaces)
             self._pipelines[pipeline_name] = pipeline
             pipeline.start()
         return pipeline.pool.submit(expid, priority, due_date, flush, pipeline_name)
@@ -437,7 +601,7 @@ class Scheduler:
         for pipeline in self._pipelines.values():
             if rid in pipeline.pool.runs:
                 run = pipeline.pool.runs[rid]
-                if run.status == RunStatus.running or run.status == RunStatus.paused:
+                if run.status in (RunStatus.running, RunStatus.paused, RunStatus.idle):
                     run.termination_requested = True
                 else:
                     self.delete(rid)
@@ -450,32 +614,28 @@ class Scheduler:
         Must not be modified."""
         return self.notifier.raw_view

-    def check_pause(self, rid):
+    async def check_pause(self, rid):
         """Returns ``True`` if there is a condition that could make ``pause``
         not return immediately (termination requested or higher priority run).

-        The typical purpose of this function is to check from a kernel
-        whether returning control to the host and pausing would have an effect,
-        in order to avoid the cost of switching kernels in the common case
-        where ``pause`` does nothing.
+        This is typically used to check from a kernel whether pausing would
+        have any effect, in order to avoid the cost of switching kernels in
+        the common case where ``pause`` does nothing.

-        This function does not have side effects, and does not have to be
-        followed by a call to ``pause``.
+        This function returns quickly, and does not have to be followed by a
+        call to ``pause``.
         """
-        for pipeline in self._pipelines.values():
-            if rid in pipeline.pool.runs:
-                run = pipeline.pool.runs[rid]
-                if run.status != RunStatus.running:
-                    return False
-                if run.termination_requested:
-                    return True
+        for p in self._pipelines.values():
+            if rid in p.pool.runs:
+                pipeline = p
+                break
+        else:
+            raise KeyError("RID not found")

-                prepared_runs = filter(lambda r: r.status == RunStatus.prepare_done,
-                                       pipeline.pool.runs.values())
-                try:
-                    r = max(prepared_runs, key=lambda r: r.priority_key())
-                except ValueError:
-                    # prepared_runs is an empty sequence
-                    return False
-                return r.priority_key() > run.priority_key()
-        raise KeyError("RID not found")
+        run = pipeline.pool.runs[rid]
+        if run.status != RunStatus.running:
+            return False
+        if run.termination_requested:
+            return True
+
+        return run != (await pipeline._run.highest_priority_run())
diff --git a/artiq/master/worker.py b/artiq/master/worker.py
index 36d5a202f..9b758c743 100644
--- a/artiq/master/worker.py
+++ b/artiq/master/worker.py
@@ -10,11 +10,27 @@ from sipyco.logging_tools import LogParser
 from sipyco.packed_exceptions import current_exc_packed

 from artiq.tools import asyncio_wait_or_cancel
+from enum import Enum, unique


 logger = logging.getLogger(__name__)


+@unique
+class RunResult(Enum):
+    completed = 0
+    running = 1
+    idle = 2
+
+
+@unique
+class ResumeAction(Enum):
+    check_still_idle = "check_still_idle"
+    pause = "pause"
+    resume = "resume"
+    request_termination = "request_termination"
+
+
 class WorkerTimeout(Exception):
     pass

@@ -212,9 +228,12 @@ class Worker:
                 raise WorkerWatchdogTimeout
             action = obj["action"]
             if action == "completed":
-                return True
+                return RunResult.completed
+            elif action == "idle":
+                is_idle = obj["kwargs"]["is_idle"]
+                return RunResult.idle if is_idle else RunResult.running
             elif action == "pause":
-                return False
+                return RunResult.running
             elif action == "exception":
                 raise WorkerInternalException
             elif action == "create_watchdog":
@@ -226,7 +245,10 @@ class Worker:
             else:
                 func = self.handlers[action]
             try:
-                data = func(*obj["args"], **obj["kwargs"])
+                if asyncio.iscoroutinefunction(func):
+                    data = (await func(*obj["args"], **obj["kwargs"]))
+                else:
+                    data = func(*obj["args"], **obj["kwargs"])
                 reply = {"status": "ok", "data": data}
             except:
                 reply = {
@@ -275,20 +297,25 @@ class Worker:
         await self._worker_action({"action": "prepare"})

     async def run(self):
-        completed = await self._worker_action({"action": "run"})
-        if not completed:
+        run_result = await self._worker_action({"action": "run"})
+        if run_result != RunResult.completed:
             self.yield_time = time.monotonic()
-        return completed
+        return run_result

-    async def resume(self, request_termination):
+    async def resume(self, resume_action):
         stop_duration = time.monotonic() - self.yield_time
-        for wid, expiry in self.watchdogs:
+        for wid in self.watchdogs.items():
             self.watchdogs[wid] += stop_duration
-        completed = await self._worker_action({"status": "ok",
-                                               "data": request_termination})
-        if not completed:
+        timeout = None
+        if resume_action == ResumeAction.check_still_idle:
+            timeout = 1.0
+        run_result = await self._worker_action({
+            "status": "ok",
+            "data": resume_action.value
+        }, timeout)
+        if not run_result:
             self.yield_time = time.monotonic()
-        return completed
+        return run_result

     async def analyze(self):
         await self._worker_action({"action": "analyze"})
@@ -300,8 +327,10 @@ class Worker:
         await self._create_process(logging.WARNING)
         r = dict()

-        def register(class_name, name, arginfo, scheduler_defaults):
-            r[class_name] = {"name": name, "arginfo": arginfo, "scheduler_defaults": scheduler_defaults}
+        def register(class_name, name, arginfo, argument_ui, scheduler_defaults):
+            r[class_name] = {"name": name, "arginfo": arginfo,
+                             "scheduler_defaults": scheduler_defaults,
+                             "argument_ui": argument_ui}
         self.register_experiment = register
         await self._worker_action({"action": "examine", "file": file},
                                   timeout)
diff --git a/artiq/master/worker_db.py b/artiq/master/worker_db.py
index 172846145..b6c431aaf 100644
--- a/artiq/master/worker_db.py
+++ b/artiq/master/worker_db.py
@@ -5,8 +5,10 @@ standalone command line tools).
 """

 from operator import setitem
+import h5py
 import importlib
 import logging
+import numpy

 from sipyco.sync_struct import Notifier
 from sipyco.pc_rpc import AutoTarget, Client, BestEffortClient
@@ -159,12 +161,12 @@ class DatasetManager:
     def get(self, key, archive=False):
         if key in self.local:
             return self.local[key]
-
+
         data = self.ddb.get(key)
         if archive:
-            if key in self.archive:
-                logger.warning("Dataset '%s' is already in archive, "
-                               "overwriting", key, stack_info=True)
+            # if key in self.archive:
+            #     logger.warning("Dataset '%s' is already in archive, "
+            #                    "overwriting", key, stack_info=True)
             self.archive[key] = data
         return data

@@ -182,6 +184,10 @@ def _write(group, k, v):
     # Add context to exception message when the user writes a dataset that is
     # not representable in HDF5.
     try:
+        if isinstance(v, list):
+            v = numpy.asarray(v)
+            if v.dtype.type == numpy.unicode_:
+                v = numpy.array(v, dtype=h5py.special_dtype(vlen=str))
         group[k] = v
     except TypeError as e:
         raise TypeError("Error writing dataset '{}' of type '{}': {}".format(
diff --git a/artiq/master/worker_impl.py b/artiq/master/worker_impl.py
index 784e4297a..53e805ec3 100644
--- a/artiq/master/worker_impl.py
+++ b/artiq/master/worker_impl.py
@@ -30,6 +30,8 @@ from artiq.compiler import import_cache
 from artiq.coredevice.core import CompileError, host_only, _render_diagnostic
 from artiq import __version__ as artiq_version

+import logging
+logger = logging.getLogger(__name__)

 ipc = None

@@ -95,11 +97,82 @@ class Scheduler:
         self.expid = expid
         self.priority = priority

-    pause_noexc = staticmethod(make_parent_action("pause"))
+    idle_parent = staticmethod(make_parent_action("idle"))
+    pause_parent = staticmethod(make_parent_action("pause"))
+
     @host_only
     def pause(self):
-        if self.pause_noexc():
+        cmd = self.pause_parent()
+        if cmd == "request_termination":
             raise TerminationRequested
+        elif cmd == "resume":
+            return
+        else:
+            raise ValueError(
+                "Unexpected master command after pause: '{}'".format(cmd))
+
+    @host_only
+    def idle(self, callback):
+        """Suspend execution until some condition is fulfilled.
+
+        This allows an experiment to voluntarily cede to other experiments,
+        even if the latter have in general got a lower priority. An experiment
+        calling this method needs to ensure that any connection to the core
+        device has been closed beforehand.
+        The difference to the :meth:`~artiq.master.worker_impl.pause` method
+        can be summarised as follows:
+            - Paused experiments will run unless there is another experiment
+                with higher priority
+            - Idle experiments will not run unless some condition is satisfied
+
+        The scheduler regularly checks whether an experiment should remain
+        idle by calling the ``callback`` argument passed to this method.
+        This function is thus used to check whether the relevant condition for
+        resuming execution is satisfied and should return accordingly.
+
+        :param callback: Function to call by scheduler when checking whether
+            the experiment should remain idle.
+            If callback returns True, experiment will idle; if it returns
+            False, the scheduler will consider the experiment eligible to run
+            and will execute it as soon as there no higher-priority
+            experiments that also want to run.
+
+        Example::
+
+            MyExp(EnvExperiment):
+                def build(self):
+                    self.setattr_device("core")
+                    self.setattr_device("scheduler")
+
+                def run(self):
+                    while True:
+                        self.core.close()
+                        self.scheduler.idle(check_idle)
+                        self.do()
+
+                def check_idle(self):
+                    condition = <describe when experiment should resume>
+                    return False if condition else True
+        """
+        while True:
+            resume = self.idle_raw(callback)
+            if resume:
+                return
+            self.pause()
+
+    @host_only
+    def idle_raw(self, callback):
+        while True:
+            cmd = self.idle_parent(is_idle=bool(callback()))
+            if cmd == "check_still_idle":
+                continue
+            elif cmd == "resume":
+                return True
+            elif cmd == "pause":
+                return False
+            else:
+                raise ValueError(
+                    "Unexpected master command while idle: '{}'".format(cmd))

     _check_pause = staticmethod(make_parent_action("scheduler_check_pause"))
     def check_pause(self, rid=None) -> TBool:
@@ -175,13 +248,18 @@ def examine(device_mgr, dataset_mgr, file):
                     name = exp_class.__doc__.strip().splitlines()[0].strip()
                     if name[-1] == ".":
                         name = name[:-1]
+                argument_ui = None
+                if hasattr(exp_class, "argument_ui"):
+                    argument_ui = exp_class.argument_ui
                 argument_mgr = TraceArgumentManager()
                 scheduler_defaults = {}
                 cls = exp_class((device_mgr, dataset_mgr, argument_mgr, scheduler_defaults))
                 arginfo = OrderedDict(
                     (k, (proc.describe(), group, tooltip))
                     for k, (proc, group, tooltip) in argument_mgr.requested_args.items())
-                register_experiment(class_name, name, arginfo, scheduler_defaults)
+
+                register_experiment(class_name, name, arginfo, argument_ui,
+                                    scheduler_defaults)
     finally:
         new_keys = set(sys.modules.keys())
         for key in new_keys - previous_keys:
diff --git a/artiq/test/test_scheduler.py b/artiq/test/test_scheduler.py
index ad4f243bd..996bee38b 100644
--- a/artiq/test/test_scheduler.py
+++ b/artiq/test/test_scheduler.py
@@ -31,6 +31,34 @@ class BackgroundExperiment(EnvExperiment):
                              broadcast=True, archive=False)


+class IdleExperiment(EnvExperiment):
+    def build(self):
+        self.setattr_device("scheduler")
+
+    def _be_idle(self):
+        return self.get_dataset("be_idle", archive=False)
+
+    def run(self):
+        def is_idle():
+            if self.get_dataset("take_long_in_idle", archive=False):
+                sleep(10.0)
+            return self._be_idle()
+
+        try:
+            while True:
+                if not self._be_idle():
+                    sleep(0.2)
+                    self.scheduler.pause()
+                    continue
+
+                if not self.scheduler.idle(is_idle):
+                    self.scheduler.pause()
+
+        except TerminationRequested:
+            self.set_dataset(
+                "termination_ok", True, broadcast=True, archive=False)
+
+
 class CheckPauseBackgroundExperiment(EnvExperiment):
     def build(self):
         self.setattr_device("scheduler")
@@ -94,7 +122,7 @@ class SchedulerCase(unittest.TestCase):

     def test_steps(self):
         loop = self.loop
-        scheduler = Scheduler(_RIDCounter(0), dict(), None)
+        scheduler = Scheduler(_RIDCounter(0), dict(), None, None)
         expid = _get_expid("EmptyExperiment")

         expect = _get_basic_steps(1, expid)
@@ -133,7 +161,7 @@ class SchedulerCase(unittest.TestCase):
         prepare."""
         loop = self.loop
         handlers = {}
-        scheduler = Scheduler(_RIDCounter(0), handlers, None)
+        scheduler = Scheduler(_RIDCounter(0), handlers, None, None)
         handlers["scheduler_check_pause"] = scheduler.check_pause

         expid_empty = _get_expid("EmptyExperiment")
@@ -297,7 +325,7 @@ class SchedulerCase(unittest.TestCase):
         handlers = {
             "update_dataset": check_termination
         }
-        scheduler = Scheduler(_RIDCounter(0), handlers, None)
+        scheduler = Scheduler(_RIDCounter(0), handlers, None, None)

         expid_bg = _get_expid("BackgroundExperiment")
         expid = _get_expid("EmptyExperiment")
@@ -335,17 +363,18 @@ class SchedulerCase(unittest.TestCase):
         scheduler.start()
         scheduler.submit("main", expid_bg, -99, None, False)
         loop.run_until_complete(background_running.wait())
-        self.assertFalse(scheduler.check_pause(0))
+        check_pause_0 = lambda: loop.run_until_complete(scheduler.check_pause(0))
+        self.assertFalse(check_pause_0())
         scheduler.submit("main", expid, 0, None, False)
-        self.assertFalse(scheduler.check_pause(0))
+        self.assertFalse(check_pause_0())
         loop.run_until_complete(empty_ready.wait())
-        self.assertTrue(scheduler.check_pause(0))
+        self.assertTrue(check_pause_0())
         loop.run_until_complete(empty_completed.wait())
-        self.assertFalse(scheduler.check_pause(0))
+        self.assertFalse(check_pause_0())

         self.assertFalse(termination_ok)
         scheduler.request_termination(0)
-        self.assertTrue(scheduler.check_pause(0))
+        self.assertTrue(check_pause_0())
         loop.run_until_complete(background_completed.wait())
         self.assertTrue(termination_ok)

@@ -355,7 +384,7 @@ class SchedulerCase(unittest.TestCase):
         """Check scheduler exits with experiments still running"""
         loop = self.loop

-        scheduler = Scheduler(_RIDCounter(0), {}, None)
+        scheduler = Scheduler(_RIDCounter(0), {}, None, None)

         expid_bg = _get_expid("BackgroundExperiment")
         # Suppress the SystemExit backtrace when worker process is killed.
@@ -396,7 +425,7 @@ class SchedulerCase(unittest.TestCase):

     def test_flush(self):
         loop = self.loop
-        scheduler = Scheduler(_RIDCounter(0), dict(), None)
+        scheduler = Scheduler(_RIDCounter(0), dict(), None, None)
         expid = _get_expid("EmptyExperiment")

         expect = _get_basic_steps(1, expid, 1, True)
@@ -428,5 +457,180 @@ class SchedulerCase(unittest.TestCase):
         loop.run_until_complete(done.wait())
         loop.run_until_complete(scheduler.stop())

+    def _make_status_events(self, rid, previous_notify=None):
+        status_events = {
+            key: asyncio.Event()
+            for key in ("prepare_done", "running", "paused", "run_done",
+                        "deleting", "idle")
+        }
+
+        def notify(mod):
+            if (mod["path"] == [rid] and mod["action"] == "setitem"
+                    and mod["key"] == "status"):
+                event = status_events.get(mod["value"], None)
+                if event:
+                    event.set()
+            if previous_notify:
+                previous_notify(mod)
+
+        return status_events, notify
+
+    def _make_scheduler_for_idle_test(self):
+        class Flags:
+            def __init__(self):
+                self.be_idle = False
+                self.take_long_in_idle = False
+                self.termination_ok = False
+
+        flags = Flags()
+
+        def get_dataset(name):
+            return getattr(flags, name)
+
+        def check_termination(mod):
+            self.assertEqual(
+                mod, {
+                    "action": "setitem",
+                    "key": "termination_ok",
+                    "value": (False, True),
+                    "path": []
+                })
+            flags.termination_ok = True
+
+        handlers = {
+            "get_dataset": get_dataset,
+            "update_dataset": check_termination
+        }
+        scheduler = Scheduler(_RIDCounter(0), handlers, None, None)
+
+        status_events, notify = self._make_status_events(0)
+        scheduler.notifier.publish = notify
+
+        scheduler.start()
+
+        expid_idle = _get_expid("IdleExperiment")
+        # Suppress the SystemExit backtrace when worker process is killed.
+        expid_idle["log_level"] = logging.CRITICAL
+        scheduler.submit("main", expid_idle, 0, None, False)
+
+        return scheduler, status_events, flags
+
+    def test_close_with_idle_running(self):
+        """Check scheduler exits with experiment still idle"""
+        loop = self.loop
+        scheduler, status_events, flags = self._make_scheduler_for_idle_test()
+        loop.run_until_complete(status_events["running"].wait())
+        flags.be_idle = True
+        loop.run_until_complete(status_events["idle"].wait())
+        loop.run_until_complete(scheduler.stop())
+
+    def test_close_with_prepared_bg(self):
+        """Check scheduler exits when there is still a prepare_done experiment"""
+        loop = self.loop
+        scheduler, status_events, _ = self._make_scheduler_for_idle_test()
+
+        loop.run_until_complete(status_events["running"].wait())
+
+        # Submit lower-priority experiment that is still waiting to be run when
+        # the scheduler is terminated.
+        expid = _get_expid("EmptyExperiment")
+        scheduler.submit("main", expid, -1, None, False)
+
+        loop.run_until_complete(scheduler.stop())
+
+    def test_resume_idle(self):
+        """Check scheduler resumes previously idle experiments"""
+        loop = self.loop
+        scheduler, status_events, flags = self._make_scheduler_for_idle_test()
+        loop.run_until_complete(status_events["running"].wait())
+
+        # Make sure we can un-idle by returning False from the idle callback.
+        flags.be_idle = True
+        loop.run_until_complete(status_events["idle"].wait())
+
+        status_events["running"].clear()
+        flags.be_idle = False
+        loop.run_until_complete(status_events["running"].wait())
+
+        # Make sure we can un-idle by requesting termination.
+        flags.be_idle = True
+        loop.run_until_complete(status_events["idle"].wait())
+
+        self.assertFalse(flags.termination_ok)
+        scheduler.request_termination(0)
+        loop.run_until_complete(status_events["deleting"].wait())
+        self.assertTrue(flags.termination_ok)
+
+        loop.run_until_complete(scheduler.stop())
+
+    def test_idle_bg(self):
+        """Check scheduler runs lower-priority experiments while idle"""
+        loop = self.loop
+        scheduler, idle_status_events, flags = self._make_scheduler_for_idle_test()
+
+        bg_status_events, notify = self._make_status_events(
+            1, scheduler.notifier.publish)
+        scheduler.notifier.publish = notify
+
+        loop.run_until_complete(idle_status_events["running"].wait())
+
+        # Submit experiment with lower priority.
+        expid = _get_expid("BackgroundExperiment")
+        scheduler.submit("main", expid, -1, None, False)
+
+        check_pause_1 = lambda: loop.run_until_complete(scheduler.check_pause(1))
+
+        loop.run_until_complete(bg_status_events["prepare_done"].wait())
+
+        flags.be_idle = True
+        loop.run_until_complete(bg_status_events["running"].wait())
+        self.assertFalse(check_pause_1())
+
+        idle_status_events["running"].clear()
+        flags.be_idle = False
+        loop.run_until_complete(idle_status_events["running"].wait())
+
+        bg_status_events["running"].clear()
+        flags.be_idle = True
+        self.assertFalse(check_pause_1())
+        loop.run_until_complete(bg_status_events["running"].wait())
+
+        idle_status_events["running"].clear()
+        flags.be_idle = False
+        self.assertTrue(check_pause_1())
+        loop.run_until_complete(idle_status_events["running"].wait())
+
+        scheduler.request_termination(0)
+        scheduler.request_termination(1)
+        loop.run_until_complete(bg_status_events["deleting"].wait())
+
+        loop.run_until_complete(scheduler.stop())
+
+    def test_idle_timeout(self):
+        """Check that blocking is_idle_callback times out"""
+        loop = self.loop
+        scheduler, status_events, flags = self._make_scheduler_for_idle_test()
+
+        # Submit empty experiment with lower priority.
+        empty_status_events, notify = self._make_status_events(
+            1, scheduler.notifier.publish)
+        scheduler.notifier.publish = notify
+
+        expid = _get_expid("EmptyExperiment")
+        scheduler.submit("main", expid, -1, None, False)
+
+        # Make the is_idle_callback in block; silencing the expected error
+        # message in the log output.
+        logging.disable(logging.ERROR)
+        flags.be_idle = True
+        flags.take_long_in_idle = True
+        loop.run_until_complete(status_events["deleting"].wait())
+        logging.disable(logging.NOTSET)
+
+        # Make sure EmptyExperiment completes normally now.
+        loop.run_until_complete(empty_status_events["run_done"].wait())
+
+        loop.run_until_complete(scheduler.stop())
+
     def tearDown(self):
         self.loop.close()
